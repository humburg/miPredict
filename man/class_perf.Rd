% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/class_perf.R
\name{class_perf}
\alias{class_perf}
\title{Assessing model predictive performance}
\usage{
class_perf(
  predictions,
  outcome,
  metrics = c("auc", "specificity", "sensitivity", "accuracy", "precision"),
  bootstrap = FALSE,
  iter = 2000,
  level = 0.95
)
}
\arguments{
\item{predictions}{A numeric vector of predicted class probabilities.}

\item{outcome}{A vector (numeric or factor) of outcome labels.}

\item{metrics}{Character vector indicating which performance measures should be computed. One or more of \emph{auc}, \emph{specificity}, \emph{sensitivity}, \emph{accuracy}, \emph{precision}.}

\item{bootstrap}{Logical indicating whether bootstrap samples should be generated from \code{data}.}

\item{iter}{Number of bootstrap iterations to use.}

\item{level}{Width of the confidence interval.}
}
\value{
A list of performance measures of the same length as \code{metrics}.
}
\description{
Compute performance metrics for logistic regression models.
}
\section{Available performance metrics:}{
Confidence intervals may be calculated for a range of performance metrics, including the AUC, specificity, sensitivity, accuracy, and precision. Of these all except AUC
depend on the choice of classification cut-off used. The metrics reported by this function are at the cut-off which maximises the sum of sensitivity and specificity,
i.e. the Youden Index.
}

\section{Using multiply imputed data:}{
To compute performance metrics from multiply imputed data, use the \code{\link[=performance]{performance()}} function instead.
}

\seealso{
\code{\link[=performance]{performance()}}
}
\author{
Peter Humburg
}
